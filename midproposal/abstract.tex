\chapter*{ABSTRACT}
\addcontentsline{toc}{chapter}{ABSTRACT}
\begin{normaltext}
    Fine-tuning large language models requires intensive hardware resources, making full fine-tuning infeasible to train under low resources constraints. Although some large language models perform better in Python code generation but they are not feasible for training in custom datasets. Addressing this gap requires efficient fine-tuning that reduces memory and computation overhead. This project aims to fine-tune Llama-2 7B for python code generation by Parameter Efficient Fine Tuning (PEFT) with QLoRA, focusing on the hardware level constraints. The training dataset is constructed from multiple open-source repositories, including FlyTec, StaQC and Alpaca 18k. Preprocessing involves filtering non-Python samples, cleaning noisy code, and formatting the data into instructionâ€“response pairs suitable for supervised fine-tuning. The fine-tuned model will be evaluated on unseen python problems. Performance will be compared with the base model Llama-2 7B to assess improvement achieved through fine-tuning Llama-2 7B. The Fine-tuned model is expected to be capable of generating python code solutions for common coding exercises, using mixture of common programming problems and LeetCode problems as a benchmark on low edge devices.
    
\vspace{18 pt}

\textit{Keywords: PEFT, QLoRA, LoRA, OPT, Hugging Face. }

\end{normaltext}