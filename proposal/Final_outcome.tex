\chapter{Expected Outcome}

\begin{normaltext}This model is expected to generate python code based on the provided textual prompts using Llama 2 7B. The fine-tuned model is expected to learn the behavior of the provided datasets, not only the facts. Basically, the model will learn how to answer rather than what to answer. The fine-tuned model is expected to achieve higher accuracy than the base model in python code generation specific domain which is expected to answer with higher accuracy to unseen problems being syntactically and logically correct with correct reasoning. This model also focuses on human readability by providing extra comments and docstring wherever required.
\vspace{18 pt}

The fine-tuned model will be runnable in low specification devices with higher
accuracy than the base model and A common end goal is to generate functional and deployable end-to-end systems that can be used in real-world settings.

\end{normaltext}