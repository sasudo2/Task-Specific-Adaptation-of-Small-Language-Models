@article{Hu2021,
  author = {Hu, Edward and Shen, Yelong and Wallis, Phil and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  title = {LoRA: Low-Rank Adaptation of Large Language Models},
  journal = {arXiv preprint arXiv:2106.09685},
  year = {2021},
  url = {https://arxiv.org/abs/2106.09685}
}

@article{Dettmers2023,
  author = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  title = {QLoRA: Efficient Finetuning of Quantized LLMs},
  journal = {arXiv preprint arXiv:2305.14314},
  year = {2023},
  url = {https://arxiv.org/abs/2305.14314}
}

@article{Govande2024,
  author = {Govande, Soham and Kang, Taeuk and Shi, Andrew},
  title = {Fine-tuning CodeLlama-7B on Synthetic Training Data for Fortran Code Generation using PEFT},
  journal = {Stanford CS224N Custom Project},
  year = {2024},
  school = {Stanford University}
}

@article{Zhang2022,
  title={OPT: Open Pre-trained Transformer Language Models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{Touvron2023Llama2,
  title = {Llama 2: Open Foundation and Fine-Tuned Chat Models},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal = {arXiv preprint arXiv:2307.09288},
  year = {2023},
  url = {https://arxiv.org/abs/2307.09288},
  note = {Meta AI}
}

@article{Kaplan2020Scaling,
  title = {Scaling Laws for Neural Language Models},
  author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal = {arXiv preprint arXiv:2001.08361},
  year = {2020},
  url = {https://arxiv.org/abs/2001.08361}
}

@article{Howard2018ULMFiT,
  title = {Universal Language Model Fine-tuning for Text Classification},
  author = {Howard, Jeremy and Ruder, Sebastian},
  journal = {arXiv preprint arXiv:1801.06146},
  year = {2018},
  url = {https://arxiv.org/abs/1801.06146}
}

@article{Li2023CoTCodeGen,
  title = {Chain-of-Thought Empowered Analysis in the Wild: A Case Study on Code Generation},
  author = {Li, Y. and others},
  journal = {arXiv preprint arXiv:2305.04417},
  year = {2023},
  url = {https://arxiv.org/abs/2305.04417}
}

