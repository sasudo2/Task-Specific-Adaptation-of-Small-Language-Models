\chapter*{ABSTRACT}
\addcontentsline{toc}{chapter}{Abstract}
\begin{normaltext}
    Fine-tuning large language models will require intensive hardware resources, making full fine-tuning infeasible to train under low resouces constraints. Although some large language models are better in python code generation but they are not feasible for training in custom datasets.Addressing this gap requires efficient fine-tuning that requires reducing memory and computation overhead. This project aims to fine-tune Llama 2 7B for python code generation by Parameter Efficient Fine Tuning (PEFT) with QLoRA, focusing on the hardware level constraints. The training dataset is constructed from multiple open-source repositories, including FlyTec, StaQC and Alpaca 18k. Preprocessing involves filtering non-Python samples, cleaning noisy code, and formatting the data into instructionâ€“response pairs suitable for supervised fine-tuning. The fine-tuned model will be evaluated on unseen python problems. Evauation is performed using set of coding problems. Performence will be compared with the base model Llama 2 7B to assess improvement achieved through fine-tuning Llama 2 7B. The Fine-tuned model will be capable of generating python code solutions for common coding exercises, using mixture of common programming problems and LeetCode problems as a benchmark on low edge devices. 
    
\vspace{18 pt}

\textit{Keywords: PEFT, QLoRA, LoRA, OPT, Hugging Face. }

\end{normaltext}