{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd39a727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading TACO dataset... This may take a few minutes.\n",
      "Error downloading dataset: Dataset scripts are no longer supported, but found TACO.py\n",
      "\n",
      "Trying alternative approach...\n",
      "\n",
      "Available files:\n",
      "  ALL/test-00000-of-00001.parquet\n",
      "  ALL/train-00000-of-00009.parquet\n",
      "  ALL/train-00001-of-00009.parquet\n",
      "  ALL/train-00002-of-00009.parquet\n",
      "  ALL/train-00003-of-00009.parquet\n",
      "  ALL/train-00004-of-00009.parquet\n",
      "  ALL/train-00005-of-00009.parquet\n",
      "  ALL/train-00006-of-00009.parquet\n",
      "  ALL/train-00007-of-00009.parquet\n",
      "  ALL/train-00008-of-00009.parquet\n",
      "  test/data-00000-of-00001.arrow\n",
      "  train/data-00000-of-00009.arrow\n",
      "  train/data-00001-of-00009.arrow\n",
      "  train/data-00002-of-00009.arrow\n",
      "  train/data-00003-of-00009.arrow\n",
      "  train/data-00004-of-00009.arrow\n",
      "  train/data-00005-of-00009.arrow\n",
      "  train/data-00006-of-00009.arrow\n",
      "  train/data-00007-of-00009.arrow\n",
      "  train/data-00008-of-00009.arrow\n",
      "\n",
      "Downloading 20 files...\n",
      "✓ Downloaded: ALL/test-00000-of-00001.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/test-00000-of-00001.parquet\n",
      "✓ Downloaded: ALL/train-00000-of-00009.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/train-00000-of-00009.parquet\n",
      "✓ Downloaded: ALL/train-00001-of-00009.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/train-00001-of-00009.parquet\n",
      "✓ Downloaded: ALL/train-00002-of-00009.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/train-00002-of-00009.parquet\n",
      "✓ Downloaded: ALL/train-00003-of-00009.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/train-00003-of-00009.parquet\n",
      "✓ Downloaded: ALL/train-00004-of-00009.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/train-00004-of-00009.parquet\n",
      "✓ Downloaded: ALL/train-00005-of-00009.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/train-00005-of-00009.parquet\n",
      "✓ Downloaded: ALL/train-00006-of-00009.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/train-00006-of-00009.parquet\n",
      "✓ Downloaded: ALL/train-00007-of-00009.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/train-00007-of-00009.parquet\n",
      "✓ Downloaded: ALL/train-00008-of-00009.parquet\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL/train-00008-of-00009.parquet\n",
      "✓ Downloaded: test/data-00000-of-00001.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/test/data-00000-of-00001.arrow\n",
      "✓ Downloaded: train/data-00000-of-00009.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/train/data-00000-of-00009.arrow\n",
      "✓ Downloaded: train/data-00001-of-00009.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/train/data-00001-of-00009.arrow\n",
      "✓ Downloaded: train/data-00002-of-00009.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/train/data-00002-of-00009.arrow\n",
      "✓ Downloaded: train/data-00003-of-00009.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/train/data-00003-of-00009.arrow\n",
      "✓ Downloaded: train/data-00004-of-00009.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/train/data-00004-of-00009.arrow\n",
      "✓ Downloaded: train/data-00005-of-00009.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/train/data-00005-of-00009.arrow\n",
      "✓ Downloaded: train/data-00006-of-00009.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/train/data-00006-of-00009.arrow\n",
      "✓ Downloaded: train/data-00007-of-00009.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/train/data-00007-of-00009.arrow\n",
      "✓ Downloaded: train/data-00008-of-00009.arrow\n",
      "  Location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/train/data-00008-of-00009.arrow\n",
      "\n",
      "================================================================================\n",
      "DOWNLOAD SUMMARY:\n",
      "================================================================================\n",
      "Total files downloaded: 20\n",
      "Base location: /home/sanja/.cache/huggingface/hub/datasets--BAAI--TACO/snapshots/d593ed0a2becbbc952230bb89be09189bf1056dc/ALL\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "from huggingface_hub import list_repo_tree\n",
    "try:\n",
    "    files = list_repo_tree(\"BAAI/TACO\", repo_type=\"dataset\", recursive=True)\n",
    "    print(f\"\\nAvailable files:\")\n",
    "    file_list = [file.path for file in files if file.path.endswith(('.arrow', '.parquet'))]\n",
    "    for file_path in file_list[:20]:  # Show first 20\n",
    "        print(f\"  {file_path}\")\n",
    "    \n",
    "    # Download all arrow files\n",
    "    print(f\"\\nDownloading {len(file_list)} files...\")\n",
    "    downloaded_paths = []\n",
    "    for file_path in file_list:\n",
    "        try:\n",
    "            local_path = hf_hub_download(\n",
    "                repo_id=\"BAAI/TACO\",\n",
    "                filename=file_path,\n",
    "                repo_type=\"dataset\"\n",
    "            )\n",
    "            downloaded_paths.append(local_path)\n",
    "            print(f\"✓ Downloaded: {file_path}\")\n",
    "            print(f\"  Location: {local_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"✗ Failed to download {file_path}: {e}\")\n",
    "    \n",
    "    # Show summary of download locations\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"DOWNLOAD SUMMARY:\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Total files downloaded: {len(downloaded_paths)}\")\n",
    "    if downloaded_paths:\n",
    "        print(f\"Base location: {os.path.dirname(downloaded_paths[0])}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error in alternative approach: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a3777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7a8e2027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV written to: /mnt/c/users/sanja/coded/minor/Notebooks/taco_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import os\n",
    "\n",
    "output_path = \"taco_cleaned.csv\"\n",
    "\n",
    "# If CSV already exists, do not overwrite; skip writing\n",
    "if os.path.exists(output_path):\n",
    "    print(f\"CSV already exists, skipping write: {os.path.abspath(output_path)}\")\n",
    "else:\n",
    "    parquet_downloaded_paths = downloaded_paths[:10]\n",
    "    header_written = False\n",
    "\n",
    "    def has_solution(v) -> bool:\n",
    "        if isinstance(v, list):\n",
    "            return len(v) > 0\n",
    "        try:\n",
    "            parsed = ast.literal_eval(v)\n",
    "            if isinstance(parsed, list):\n",
    "                return len(parsed) > 0\n",
    "        except Exception:\n",
    "            pass\n",
    "        return v not in (\"[]\", \"\", None)\n",
    "\n",
    "    def extract_first_solution(val):\n",
    "        try:\n",
    "            if isinstance(val, list):\n",
    "                return val[0] if val else None\n",
    "            parsed = ast.literal_eval(val)\n",
    "            return parsed[0] if parsed else None\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    for path in parquet_downloaded_paths:\n",
    "        df = pd.read_parquet(path)\n",
    "        df = df.drop([\n",
    "            \"starter_code\", \"name\", \"source\", \"skill_types\", \"url\",\n",
    "            \"Expected Auxiliary Space\", \"input_output\", \"time_limit\", \"raw_tags\", \"date\",\n",
    "            \"picture_num\", \"memory_limit\", \"Expected Time Complexity\"\n",
    "        ], axis=1, errors=\"ignore\")\n",
    "\n",
    "        # Filter rows with non-empty solutions and normalize to first entry\n",
    "        df = df[df[\"solutions\"].apply(has_solution)].reset_index(drop=True)\n",
    "        df[\"solutions\"] = df[\"solutions\"].apply(extract_first_solution)\n",
    "\n",
    "        # Write directly to CSV, appending after the first chunk\n",
    "        df.to_csv(output_path, mode=\"a\", header=not header_written, index=False)\n",
    "        header_written = True\n",
    "\n",
    "    print(f\"CSV written to: {os.path.abspath(output_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1ea6df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>solutions</th>\n",
       "      <th>starter_code</th>\n",
       "      <th>input_output</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>raw_tags</th>\n",
       "      <th>name</th>\n",
       "      <th>source</th>\n",
       "      <th>tags</th>\n",
       "      <th>skill_types</th>\n",
       "      <th>url</th>\n",
       "      <th>Expected Auxiliary Space</th>\n",
       "      <th>time_limit</th>\n",
       "      <th>date</th>\n",
       "      <th>picture_num</th>\n",
       "      <th>memory_limit</th>\n",
       "      <th>Expected Time Complexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The city park of IT City contains n east to we...</td>\n",
       "      <td>[\"n = int(input())\\ncn5 = n * (n - 1) // 2 * (...</td>\n",
       "      <td></td>\n",
       "      <td>{\"inputs\": [\"5\\n\", \"6\\n\", \"7\\n\", \"15\\n\", \"17\\n...</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>['combinatorics', 'math']</td>\n",
       "      <td>None</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>['Combinatorics', 'Mathematics']</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://codeforces.com/problemset/problem/630/H</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zookeeper is buying a carton of fruit to feed ...</td>\n",
       "      <td>[\"hist = [0] * 1000005\\n\\ndef solve(n, s):\\n\\t...</td>\n",
       "      <td></td>\n",
       "      <td>{\"inputs\": [\"4\\n0110\\n\", \"7\\n1101001\\n\", \"12\\n...</td>\n",
       "      <td>VERY_HARD</td>\n",
       "      <td>['data structures', 'binary search', 'dp', 'tw...</td>\n",
       "      <td>None</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>['Sorting', 'Amortized analysis', 'Dynamic pro...</td>\n",
       "      <td>['Dynamic programming', 'Data structures', 'So...</td>\n",
       "      <td>https://codeforces.com/problemset/problem/1428/F</td>\n",
       "      <td>None</td>\n",
       "      <td>2 seconds</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>0</td>\n",
       "      <td>256 megabytes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sasha and Kolya decided to get drunk with Coke...</td>\n",
       "      <td>[\"from collections import deque\\nMAX_A = 1000\\...</td>\n",
       "      <td></td>\n",
       "      <td>{\"inputs\": [\"852 10\\n668 1000 1000 1000 1000 1...</td>\n",
       "      <td>HARD</td>\n",
       "      <td>['shortest paths', 'dfs and similar', 'graphs']</td>\n",
       "      <td>None</td>\n",
       "      <td>codeforces</td>\n",
       "      <td>['Graph algorithms', 'Graph traversal', 'Short...</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://codeforces.com/problemset/problem/789/E</td>\n",
       "      <td>None</td>\n",
       "      <td>1.0 seconds</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>256.0 megabytes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Read problem statements in [Hindi], [Bengali],...</td>\n",
       "      <td>[\"p = 10 ** 9 + 7\\n\\ndef power(a, n):\\n\\tres =...</td>\n",
       "      <td></td>\n",
       "      <td>{\"inputs\": [\"2\\n2\\n2 2\\n4\\n1 2 2 6\", \"3\\n3\\n1 ...</td>\n",
       "      <td>MEDIUM_HARD</td>\n",
       "      <td>['Mathematics', 'Modular Arithmetic', 'Combina...</td>\n",
       "      <td>None</td>\n",
       "      <td>codechef</td>\n",
       "      <td>['Combinatorics', 'Mathematics']</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.codechef.com/problems/CRDGAME2</td>\n",
       "      <td>None</td>\n",
       "      <td>1 seconds</td>\n",
       "      <td>2020-07-07</td>\n",
       "      <td>0</td>\n",
       "      <td>50000 bytes</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I started this as a joke among friends, tellin...</td>\n",
       "      <td>[\"from math import *\\nDIGS = '0123456789ABCDEF...</td>\n",
       "      <td>def converter(n, decimals=0, base=pi):\\n\\t</td>\n",
       "      <td>{\"fn_name\": \"converter\", \"inputs\": [[13], [10]...</td>\n",
       "      <td>MEDIUM_HARD</td>\n",
       "      <td>['Mathematics', 'Algorithms', 'Fundamentals']</td>\n",
       "      <td>None</td>\n",
       "      <td>codewars</td>\n",
       "      <td>['Fundamentals', 'Mathematics']</td>\n",
       "      <td>[]</td>\n",
       "      <td>https://www.codewars.com/kata/5509609d1dbf20a3...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0  The city park of IT City contains n east to we...   \n",
       "1  Zookeeper is buying a carton of fruit to feed ...   \n",
       "2  Sasha and Kolya decided to get drunk with Coke...   \n",
       "3  Read problem statements in [Hindi], [Bengali],...   \n",
       "4  I started this as a joke among friends, tellin...   \n",
       "\n",
       "                                           solutions  \\\n",
       "0  [\"n = int(input())\\ncn5 = n * (n - 1) // 2 * (...   \n",
       "1  [\"hist = [0] * 1000005\\n\\ndef solve(n, s):\\n\\t...   \n",
       "2  [\"from collections import deque\\nMAX_A = 1000\\...   \n",
       "3  [\"p = 10 ** 9 + 7\\n\\ndef power(a, n):\\n\\tres =...   \n",
       "4  [\"from math import *\\nDIGS = '0123456789ABCDEF...   \n",
       "\n",
       "                                 starter_code  \\\n",
       "0                                               \n",
       "1                                               \n",
       "2                                               \n",
       "3                                               \n",
       "4  def converter(n, decimals=0, base=pi):\\n\\t   \n",
       "\n",
       "                                        input_output   difficulty  \\\n",
       "0  {\"inputs\": [\"5\\n\", \"6\\n\", \"7\\n\", \"15\\n\", \"17\\n...       MEDIUM   \n",
       "1  {\"inputs\": [\"4\\n0110\\n\", \"7\\n1101001\\n\", \"12\\n...    VERY_HARD   \n",
       "2  {\"inputs\": [\"852 10\\n668 1000 1000 1000 1000 1...         HARD   \n",
       "3  {\"inputs\": [\"2\\n2\\n2 2\\n4\\n1 2 2 6\", \"3\\n3\\n1 ...  MEDIUM_HARD   \n",
       "4  {\"fn_name\": \"converter\", \"inputs\": [[13], [10]...  MEDIUM_HARD   \n",
       "\n",
       "                                            raw_tags  name      source  \\\n",
       "0                          ['combinatorics', 'math']  None  codeforces   \n",
       "1  ['data structures', 'binary search', 'dp', 'tw...  None  codeforces   \n",
       "2    ['shortest paths', 'dfs and similar', 'graphs']  None  codeforces   \n",
       "3  ['Mathematics', 'Modular Arithmetic', 'Combina...  None    codechef   \n",
       "4      ['Mathematics', 'Algorithms', 'Fundamentals']  None    codewars   \n",
       "\n",
       "                                                tags  \\\n",
       "0                   ['Combinatorics', 'Mathematics']   \n",
       "1  ['Sorting', 'Amortized analysis', 'Dynamic pro...   \n",
       "2  ['Graph algorithms', 'Graph traversal', 'Short...   \n",
       "3                   ['Combinatorics', 'Mathematics']   \n",
       "4                    ['Fundamentals', 'Mathematics']   \n",
       "\n",
       "                                         skill_types  \\\n",
       "0                                                 []   \n",
       "1  ['Dynamic programming', 'Data structures', 'So...   \n",
       "2                                                 []   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                                 url Expected Auxiliary Space  \\\n",
       "0    https://codeforces.com/problemset/problem/630/H                     None   \n",
       "1   https://codeforces.com/problemset/problem/1428/F                     None   \n",
       "2    https://codeforces.com/problemset/problem/789/E                     None   \n",
       "3         https://www.codechef.com/problems/CRDGAME2                     None   \n",
       "4  https://www.codewars.com/kata/5509609d1dbf20a3...                     None   \n",
       "\n",
       "    time_limit        date picture_num     memory_limit  \\\n",
       "0         None  2019-12-31        None             None   \n",
       "1    2 seconds  2020-10-17           0    256 megabytes   \n",
       "2  1.0 seconds        None        None  256.0 megabytes   \n",
       "3    1 seconds  2020-07-07           0      50000 bytes   \n",
       "4         None        None        None             None   \n",
       "\n",
       "  Expected Time Complexity  \n",
       "0                     None  \n",
       "1                     None  \n",
       "2                     None  \n",
       "3                     None  \n",
       "4                     None  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(downloaded_paths[0])\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
