{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CVg7vCeaxAt"
      },
      "outputs": [],
      "source": [
        "!pip install -U \\\n",
        "  torch transformers==4.37.2 datasets peft accelerate bitsandbytes==0.41.3 \\\n",
        "  wandb matplotlib sentencepiece huggingface_hub==0.20.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "P6n0UpBWhox6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use this for running in kaggle cli"
      ],
      "metadata": {
        "id": "3KGkPjNkJTcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env WANDB_API_KEY=api key\n",
        "import wandb\n",
        "wandb.init(project=\"llama2-python-codegen\")"
      ],
      "metadata": {
        "id": "h4cDTRppJLCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VlEL5optJPOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "P60FHJEuh27L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "7ev-mh_1zAnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "use this for kaggle cli"
      ],
      "metadata": {
        "id": "Q0O9o32hJhFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=\"huggingface api\")"
      ],
      "metadata": {
        "id": "hRjaksmEJZtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json(\"dataset.jsonl\", lines=True)\n",
        "\n",
        "print(df.head())\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "m9CDkGp_T3m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "tydZCVQ3UIYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removed: This cell was causing a dependency conflict by upgrading bitsandbytes.\n",
        "!pip install -U bitsandbytes"
      ],
      "metadata": {
        "id": "EBAi--EkXF_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bitsandbytes as bnb\n",
        "print(\"bitsandbytes version:\", bnb.__version__)"
      ],
      "metadata": {
        "id": "rrC0W-3iYIkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this are some of the dependencies that we need for this notebook"
      ],
      "metadata": {
        "id": "TiaEXGVRF06E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
      ],
      "metadata": {
        "id": "_spRMiUEFg2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "settings for this notebook ,especially the path of different directories for this notebook\n"
      ],
      "metadata": {
        "id": "e6NbOsv2F_FF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
        "DATA_PATH = \"/content/dataset.jsonl\"\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/llama2-python-lora\"\n",
        "WANDB_PROJECT = \"llama2-python-codegen\""
      ],
      "metadata": {
        "id": "rwE22okpGPxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters for this training process.here we will have actual bath size 16"
      ],
      "metadata": {
        "id": "SP4PWKtLGVmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "BATCH_SIZE = 2\n",
        "GRAD_ACCUM = 8\n",
        "LR = 2e-4\n",
        "MAX_LENGTH = 512"
      ],
      "metadata": {
        "id": "yTY5rLQ0GgnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "initialize WandB .here change the name as you are running the notebook for which epoch"
      ],
      "metadata": {
        "id": "ehcIbjb-Gjy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=WANDB_PROJECT,\n",
        "    config={\n",
        "        \"model\": \"Llama-fine-tuned\",\n",
        "        \"name\": \"lora-r8-lr2e-4-epoch1\"\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"lr\": LR,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"quantization\": \"auto\",\n",
        "        \"lora_r\": 8,\n",
        "        \"lora_alpha\": 32,\n",
        "        \"lora_dropout\": 0.1\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "KoNaEcldGn5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "code for quantization using bitsandbytes"
      ],
      "metadata": {
        "id": "NYmH9ZMDGvuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if torch.cuda.is_available():\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    )\n",
        "    device_map = \"auto\"\n",
        "else:\n",
        "    bnb_config = None\n",
        "    device_map = {\"\": \"cpu\"}"
      ],
      "metadata": {
        "id": "duAIq7mjG9Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load tokenizer"
      ],
      "metadata": {
        "id": "YyXIgd40HDGn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ],
      "metadata": {
        "id": "3eTem0HMHGRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the model and prepare for lora or 4-bit training"
      ],
      "metadata": {
        "id": "8xp1FQwPHI47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        ")\n",
        "model = prepare_model_for_kbit_training(model)"
      ],
      "metadata": {
        "id": "bIkwdDYlHLDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "configuration for lora"
      ],
      "metadata": {
        "id": "n93HskbHHX6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "M7gNfkOIHbbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "load the datasets for trainig"
      ],
      "metadata": {
        "id": "Y69WTdYIHj1J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"json\", data_files=DATA_PATH)"
      ],
      "metadata": {
        "id": "5u60QwdeHnEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tokenizer function"
      ],
      "metadata": {
        "id": "zHz8q0-SHzNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(example):\n",
        "    text = f\"<s>[INST] {example['instruction']} [/INST]\\n{example['completion']}</s>\"\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_LENGTH\n",
        "    )\n"
      ],
      "metadata": {
        "id": "jc445pxOH1_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "remove the correct columns like instruction and completion which may be like instruction and code also with respect to data"
      ],
      "metadata": {
        "id": "gn0Szqo6H6LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.map(tokenize, remove_columns=[\"instruction\", \"completion\"])"
      ],
      "metadata": {
        "id": "mFNdl2CCID1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "trainign arguments and training"
      ],
      "metadata": {
        "id": "XbxxmkBBITjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM,\n",
        "    learning_rate=LR,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    report_to=\"wandb\",\n",
        "    optim=\"paged_adamw_8bit\" if torch.cuda.is_available() else \"adamw_torch\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "VAsFHbHrIV-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "save model and tokenizer"
      ],
      "metadata": {
        "id": "4JNzl6xUIn-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(f\"{OUTPUT_DIR}/final\")\n",
        "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/final\")\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "85q5RspAh6Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2q8ZsonXIAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "usk-T25eyEo6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}