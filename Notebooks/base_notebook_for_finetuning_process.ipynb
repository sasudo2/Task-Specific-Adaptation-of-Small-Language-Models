{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CVg7vCeaxAt"
      },
      "outputs": [],
      "source": [
        "# !pip install -U torch torchvision transformers datasets peft accelerate bitsandbytes wandb matplotlib sentencepiece huggingface_hub dotenv nbformat optuna --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6n0UpBWhox6"
      },
      "outputs": [],
      "source": [
        "import os, huggingface_hub\n",
        "from dotenv import load_dotenv\n",
        "import torch\n",
        "import wandb\n",
        "from datasets import load_dataset\n",
        "import bitsandbytes\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    BitsAndBytesConfig,\n",
        "    DataCollatorForLanguageModeling\n",
        ")\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KGkPjNkJTcT"
      },
      "source": [
        "use this for running in kaggle cli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4cDTRppJLCv"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sanja/.pyenv/versions/3.12.10/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/sanja/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msanjayashrestha777\u001b[0m (\u001b[33msanjayashrestha777-thapathali-campus\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()\n",
        "\n",
        "hf_token = os.getenv(\"huggingface_token\")\n",
        "wandb_key = os.getenv(\"wandb_key\")\n",
        "\n",
        "huggingface_hub.login(token = hf_token)\n",
        "wandb.login(key = wandb_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P60FHJEuh27L"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiaEXGVRF06E"
      },
      "source": [
        "this are some of the dependencies that we need for this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_spRMiUEFg2X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6NbOsv2F_FF"
      },
      "source": [
        "settings for this notebook ,especially the path of different directories for this notebook\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rwE22okpGPxU"
      },
      "outputs": [],
      "source": [
        "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"\n",
        "DATA_PATH = \"../Datasets/train (1).jsonl\"\n",
        "OUTPUT_DIR = \"llama2-python-lora\"\n",
        "WANDB_PROJECT = \"llama2-python-codegen\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SP4PWKtLGVmf"
      },
      "source": [
        "Hyperparameters for this training process.here we will have actual bath size 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yTY5rLQ0GgnX"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 1\n",
        "BATCH_SIZE = 2\n",
        "GRAD_ACCUM = 8\n",
        "LR = 2e-4\n",
        "MAX_LENGTH = 512"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehcIbjb-Gjy9"
      },
      "source": [
        "initialize WandB .here change the name as you are running the notebook for which epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KoNaEcldGn5p"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/mnt/c/users/sanja/coded/minor/Notebooks/wandb/run-20260202_133012-f3wvuz6b</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sanjayashrestha777-thapathali-campus/llama2-python-codegen/runs/f3wvuz6b' target=\"_blank\">light-dragon-13</a></strong> to <a href='https://wandb.ai/sanjayashrestha777-thapathali-campus/llama2-python-codegen' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/sanjayashrestha777-thapathali-campus/llama2-python-codegen' target=\"_blank\">https://wandb.ai/sanjayashrestha777-thapathali-campus/llama2-python-codegen</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/sanjayashrestha777-thapathali-campus/llama2-python-codegen/runs/f3wvuz6b' target=\"_blank\">https://wandb.ai/sanjayashrestha777-thapathali-campus/llama2-python-codegen/runs/f3wvuz6b</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "&lt;wandb.sdk.wandb_run.Run object at 0x707a2c280c20&gt;"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x707a2c280c20>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.init(\n",
        "    project=WANDB_PROJECT,\n",
        "    config={\n",
        "        \"model\": \"Llama-fine-tuned\",\n",
        "        \"name\": \"lora-r8-lr2e-4-epoch1\",\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"lr\": LR,\n",
        "        \"batch_size\": BATCH_SIZE,\n",
        "        \"quantization\": \"auto\",\n",
        "        \"lora_r\": 8,\n",
        "        \"lora_alpha\": 32,\n",
        "        \"lora_dropout\": 0.1\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYmH9ZMDGvuM"
      },
      "source": [
        "code for quantization using bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "duAIq7mjG9Z-"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    bnb_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16\n",
        "    )\n",
        "    device_map = \"auto\"\n",
        "else:\n",
        "    bnb_config = None\n",
        "    device_map = {\"\": \"cpu\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyXIgd40HDGn"
      },
      "source": [
        "load tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3eTem0HMHGRm"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xp1FQwPHI47"
      },
      "source": [
        "load the model and prepare for lora or 4-bit training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bIkwdDYlHLDR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading weights: 100%|██████████| 291/291 [00:23<00:00, 12.32it/s, Materializing param=model.norm.weight]                              \n"
          ]
        }
      ],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=device_map,\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        ")\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n93HskbHHX6P"
      },
      "source": [
        "configuration for lora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7gNfkOIHbbv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 8,388,608 || all params: 6,746,804,224 || trainable%: 0.1243\n"
          ]
        }
      ],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y69WTdYIHj1J"
      },
      "source": [
        "load the datasets for trainig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5u60QwdeHnEc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 16736 examples [00:00, 25172.81 examples/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"json\", data_files=DATA_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHz8q0-SHzNB"
      },
      "source": [
        "tokenizer function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jc445pxOH1_k"
      },
      "outputs": [],
      "source": [
        "def tokenize(example):\n",
        "    text = f\"{example[\"text\"]}\"\n",
        "    return tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=MAX_LENGTH\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn0Szqo6H6LH"
      },
      "source": [
        "remove the correct columns like instruction and completion which may be like instruction and code also with respect to data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mFNdl2CCID1m"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 16736/16736 [00:18<00:00, 912.65 examples/s] \n"
          ]
        }
      ],
      "source": [
        "dataset = dataset.map(tokenize, remove_columns=[\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbxxmkBBITjw"
      },
      "source": [
        "trainign arguments and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAsFHbHrIV-P"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "warmup_ratio is deprecated and will be removed in v5.2. Use `warmup_steps` instead.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/sanja/.pyenv/versions/3.12.10/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:1181: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. Starting in PyTorch 2.9, calling checkpoint without use_reentrant will raise an exception. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='1046' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   5/1046 01:20 < 7:43:42, 0.04 it/s, Epoch 0.00/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=OUTPUT_DIR,\n",
        "    num_train_epochs=EPOCHS,\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM,\n",
        "    learning_rate=LR,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_steps=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=3,\n",
        "    report_to=\"wandb\",\n",
        "    optim=\"paged_adamw_8bit\" if torch.cuda.is_available() else \"adamw_torch\",\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_ratio=0.05\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataset=dataset['train'][:100],\n",
        "    eval_dataset = dataset['train'][100:10],\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False)\n",
        ")\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JNzl6xUIn-o"
      },
      "source": [
        "save model and tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85q5RspAh6Br"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(f\"{OUTPUT_DIR}/final\")\n",
        "tokenizer.save_pretrained(f\"{OUTPUT_DIR}/final\")\n",
        "wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "3.12.10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
