@article{Hu2021,
  author = {Hu, Edward and Shen, Yelong and Wallis, Phil and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  title = {{LoRA}: Low-Rank Adaptation of Large Language Models},
  journal = {arXiv preprint arXiv:2106.09685},
  year = {2021},
  url = {https://arxiv.org/abs/2106.09685}
}

@article{Dettmers2023,
  author = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  title = {{QLoRA}: Efficient Finetuning of Quantized {LLMs}},
  journal = {arXiv preprint arXiv:2305.14314},
  year = {2023},
  url = {https://arxiv.org/abs/2305.14314}
}

@article{Govande2024,
  author = {Govande, Soham and Kang, Taeuk and Shi, Andrew},
  title = {Fine-tuning {CodeLlama-7B} on Synthetic Training Data for {Fortran} Code Generation using {PEFT}},
  journal = {Stanford CS224N Custom Project},
  year = {2024},
  institution = {Stanford University}
}

@article{Zhang2022,
  title={{OPT}: Open Pre-trained Transformer Language Models},
  author={Zhang, Susan and Roller, Stephen and Goyal, Naman and Artetxe, Mikel and Chen, Moya and Chen, Shuohui and Dewan, Christopher and Diab, Mona and Li, Xian and Lin, Xi Victoria and others},
  journal={arXiv preprint arXiv:2205.01068},
  year={2022}
}

@article{Touvron2023Llama2,
  title = {{Llama 2}: Open Foundation and Fine-Tuned Chat Models},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal = {arXiv preprint arXiv:2307.09288},
  year = {2023},
  url = {https://arxiv.org/abs/2307.09288},
  note = {Meta AI}
}

@article{Kaplan2020Scaling,
  title = {Scaling Laws for Neural Language Models},
  author = {Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal = {arXiv preprint arXiv:2001.08361},
  year = {2020},
  url = {https://arxiv.org/abs/2001.08361}
}

@article{Howard2018ULMFiT,
  title = {Universal Language Model Fine-tuning for Text Classification},
  author = {Howard, Jeremy and Ruder, Sebastian},
  journal = {arXiv preprint arXiv:1801.06146},
  year = {2018},
  url = {https://arxiv.org/abs/1801.06146}
}

@article{Li2023CoTCodeGen,
  title = {Chain-of-Thought Empowered Analysis in the Wild: A Case Study on Code Generation},
  author = {Li, Y. and others},
  journal = {arXiv preprint arXiv:2305.04417},
  year = {2023}
}

@article{Brown2020,
  author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Deepak and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, A. and Sastry, G. and Askell, Amanda and Herbert-Voss, Alex and others},
  title = {Language Models are Few-Shot Learners},
  journal = {arXiv preprint arXiv:2009.10297},
  year = {2020}
}

@inproceedings{Papineni2002,
  author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  title = {{BLEU}: a Method for Automatic Evaluation of Machine Translation},
  booktitle = {Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics},
  pages = {311--318},
  year = {2002}
}

@inproceedings{Vaswani2017,
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\L}ukasz and Polosukhin, Illia},
  title = {Attention Is All You Need},
  booktitle = {Advances in Neural Information Processing Systems},
  pages = {5998--6008},
  year = {2017}
}

@inproceedings{Houlsby2019,
  author = {Houlsby, Neil and Giurgiu, Andrei and Jastrzebski, Stanis{\l}aw and Morrone, Bruna and de Laroussilhe, Quentin and Gesmundo, Andrea and Attariyan, Mona and Gelly, Sylvain},
  title = {Parameter-Efficient Transfer Learning for {NLP}},
  booktitle = {Proceedings of the 36th International Conference on Machine Learning},
  year = {2019}
}

@article{Liu2024DoRA,
  author = {Liu, Shih-Yang and Wang, Chien-Yi and Yin, Hongxu and Molchanov, Pavlo and Wang, Yu-Chiang Frank and Cheng, Kwang-Ting and Chen, Min-Hung},
  title = {{DoRA}: Weight-Decomposed Low-Rank Adaptation},
  journal = {arXiv preprint arXiv:2402.09353},
  year = {2024}
}

@inproceedings{Zhang2018GCE,
  author = {Zhang, Zhilu and Sabuncu, Mert R.},
  title = {Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels},
  booktitle = {Advances in Neural Information Processing Systems},
  year = {2018}
}

@article{Diehl2024Llama2Benchmark,
  author = {Diehl, Patrick and Nader, Nojoud and Moraru, Maxim and Brandt, Steven R.},
  title = {{LLM} Benchmarking with {LLaMA2}: Evaluating Code Development Performance Across Multiple Programming Languages},
  journal = {arXiv preprint arXiv:2401.00000},
  year = {2024}
}